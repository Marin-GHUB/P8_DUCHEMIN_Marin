{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f043a670-447a-41da-a3b4-18403b93c915",
   "metadata": {},
   "source": [
    "# Important Memo #\n",
    "\n",
    "Things to change when going on the cloud : \n",
    "- \"Initialization of the Spark Context\" -> conf, setMaster\n",
    "- Creating the Dataframe -> ressource_path -> \"Ressources/fruits-360_dataset/fruits-360/Training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b3722-ccf3-43ae-bbaf-9eccd599a4a6",
   "metadata": {},
   "source": [
    "# Imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2ea7b7-42b9-4c2d-8524-14520b7fce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import scipy.stats as st\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "#import random\n",
    "import re\n",
    "import time as tm\n",
    "from time import time\n",
    "#from varname import argname2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType,StringType\n",
    "from pyspark.sql.functions import udf\n",
    "#from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Image Preprocessing \n",
    "import cv2 as cv\n",
    "\n",
    "# Machine Learning for Dimensions Reduction\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db39dcb5-3e81-4f59-bd5a-fb0ba56f68d1",
   "metadata": {},
   "source": [
    "# Set-ups #\n",
    "## Initialization of the Spark context ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8b2022-694b-4d81-ad38-901c2c793413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/30 17:23:13 WARN Utils: Your hostname, muninn-System-Product-Name resolves to a loopback address: 127.0.1.1; using 192.168.1.73 instead (on interface enp0s31f6)\n",
      "21/09/30 17:23:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/muninn/anaconda3/envs/p8-env/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/30 17:23:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "t_omega = time()\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Test\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = (SparkSession.builder.appName(\"p8\").getOrCreate())\n",
    "spark.conf.set(\"spark.sql.executor.memory\", \"6g\")\n",
    "spark.conf.set(\"spark.sql.executor.cores\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe2330-7392-41fd-bc69-f2b9e0dc7a25",
   "metadata": {},
   "source": [
    "## Variables ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09175188-12db-4cd5-a2f2-daaefc4a0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "global ressource_path, image_path, preprocessed_path, data_df, des_df, dot_split\n",
    "\n",
    "# Get the paths\n",
    "\n",
    "# All\n",
    "image_path = 'Ressources/Local_Test/All_Images/'\n",
    "\n",
    "# Local Test\n",
    "ressource_path = 'Ressources/Local_Test/'\n",
    "#image_path = 'Ressources/Local_Test/Images/'\n",
    "preprocessed_path = 'Ressources/Local_Test/Preprocessed Images/'\n",
    "\n",
    "# Make a directory for the preprocessed images\n",
    "os.makedirs(preprocessed_path, exist_ok=True)\n",
    "\n",
    "# Make a list of all fruit types\n",
    "fruit_type_list = os.listdir(image_path)\n",
    "\n",
    "# Create Dataframes for later\n",
    "data_df = pd.DataFrame()\n",
    "des_df = pd.DataFrame()\n",
    "\n",
    "# Regex for later\n",
    "dot_split = re.compile(\"\\.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40a4c7-675a-4634-9339-be991ee6a990",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions to be used ##\n",
    "\n",
    "We will be using quite a number of functions to pipeline the image preprocessing, so we will define them all here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa10e83-ee68-41dc-b090-74806b988a9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DataFrame Related Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058fd8b1-253c-4b97-97a3-34b4eb65a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dataframe with fruits\n",
    "def fill_df(fruit_type, image):\n",
    "    image_name = dot_split.split(image)[0]\n",
    "    ID = f'{image_name}_{fruit_type}'\n",
    "    try:\n",
    "        fruit = {\n",
    "            'ID': ID,                    \n",
    "            'Image_name': image_name,\n",
    "            'Type_of_fruit': fruit_type,\n",
    "        }\n",
    "        return fruit\n",
    "    except:\n",
    "        fruit = {\n",
    "            'ID': ID,\n",
    "            'Image_name': image_name,\n",
    "            'Type_of_fruit': fruit_type,\n",
    "            }\n",
    "        return fruit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be868c8d-9896-40fa-9e13-2962fcf5897f",
   "metadata": {},
   "source": [
    "### Preprocessing ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7949c56-6b20-4a1c-a51e-b6afe1586939",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Individual Image Preprocessing ####\n",
    "\n",
    "##### Find the Path of the Image From the Dataframe and Load the Image #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2e32f1-1f12-4cbc-91d0-1de93515cbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the path of the image and read it\n",
    "def find_path_image(image_name, fruit_type):\n",
    "    image_type_path = image_path + fruit_type\n",
    "    path = image_type_path + '/' + image_name + '.jpg'\n",
    "    image = cv.imread(path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60eb20-832a-401d-90a2-138118b626da",
   "metadata": {},
   "source": [
    "##### Grey Scale #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba5cdc5-f7c7-4539-8fc5-576a52c64723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn the image to greyscale\n",
    "def grey_scale(image):\n",
    "    grey_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    return grey_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd975c12-ae27-464b-a2f3-476a0fadfb6d",
   "metadata": {},
   "source": [
    "##### Exposition and Contrast #####\n",
    "Function form stackoverflow user nathancy, from https://stackoverflow.com/questions/57030125/automatically-adjusting-brightness-of-image-with-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33865339-45af-4b8f-92be-2b83345c67ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def automatic_brightness_and_contrast(image, clip_hist_percent=25):\n",
    "    # Calculate grayscale histogram\n",
    "    hist = cv.calcHist([image],[0],None,[256],[0,256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Calculate cumulative distribution from the histogram\n",
    "    accumulator = []\n",
    "    accumulator.append(float(hist[0]))\n",
    "    for index in range(1, hist_size):\n",
    "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
    "\n",
    "    # Locate points to clip\n",
    "    maximum = accumulator[-1]\n",
    "    clip_hist_percent *= (maximum/100.0)\n",
    "    clip_hist_percent /= 2.0\n",
    "\n",
    "    # Locate left cut\n",
    "    minimum_gray = 0\n",
    "    while accumulator[minimum_gray] < clip_hist_percent:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Locate right cut\n",
    "    maximum_gray = hist_size -1\n",
    "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = -minimum_gray * alpha\n",
    "\n",
    "    '''\n",
    "    # Calculate new histogram with desired range and show histogram \n",
    "    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n",
    "    plt.plot(hist)\n",
    "    plt.plot(new_hist)\n",
    "    plt.xlim([0,256])\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    auto_result = cv.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return (auto_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835346e8-af29-4217-8367-b49617551c21",
   "metadata": {},
   "source": [
    "##### Noise #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9ff57b-e5ed-4665-a6ee-c5853f2b0707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering the noise of the image by blurring it\n",
    "def filtering_image(image):\n",
    "    # This argument will enable us to have an output image the same size of the input one\n",
    "    ddepth = -1\n",
    "    \n",
    "    # Creating a kernel for a normalized box filter\n",
    "    kernel = np.array(([[1,-1,1],\n",
    "                        [-1,1,-1],\n",
    "                        [1,-1,1]]), dtype=np.float32)\n",
    "    \n",
    "    # Apply the filter\n",
    "    output_image = cv.filter2D(image, ddepth, kernel)\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdc31a-3005-477e-993c-69fcbda85c88",
   "metadata": {},
   "source": [
    "##### Create Descriptors #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e91a5b-e0fa-4f7e-9a77-d514aa857fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the descriptors of the image thanks to the ORB method\n",
    "def create_descriptors(image):\n",
    "    orb = cv.ORB_create(nfeatures=1200, edgeThreshold=6)\n",
    "    kp, des = orb.detectAndCompute(image, None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad1402-b1a5-4073-96ce-42e10247f099",
   "metadata": {},
   "source": [
    "##### Save Descriptors in Dictionnary #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80281d06-4aad-4044-94b1-3a9e13a736fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a dictionnary of the descriptor for one given image\n",
    "def create_des_dict(ID, descriptors):\n",
    "    des_dict= {\n",
    "        'ID': ID,\n",
    "        'descriptors': descriptors\n",
    "    }\n",
    "    return des_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc446bb-f990-4b86-8eb9-31129bb5be60",
   "metadata": {},
   "source": [
    "#### Compile All These Steps ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657dcb06-af7d-46e0-a118-50c58651c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(ID, data_df=data_df, preprocessed_path=preprocessed_path):\n",
    "    # Getting the image's name and fruit type\n",
    "    split_ID = re.compile(\"_\")\n",
    "    fruit_type = split_ID.split(ID)[-1]\n",
    "    split_fruit = re.compile(f\"_{fruit_type}\")\n",
    "    image_name = split_fruit.split(ID)[0]\n",
    "    # Preprocessing in itself\n",
    "    image = find_path_image(image_name, fruit_type)\n",
    "    try:\n",
    "        image = grey_scale(image)\n",
    "    except:\n",
    "        print(image_name)\n",
    "        print(fruit_type)\n",
    "        print(image.shape)\n",
    "        return\n",
    "    image = automatic_brightness_and_contrast(image)\n",
    "    image = filtering_image(image)\n",
    "\n",
    "    # Saving the image\n",
    "    cv.imwrite(f\"{preprocessed_path}/{fruit_type}/{image_name}.jpg\", image)\n",
    "\n",
    "    # Creating and saving descriptors\n",
    "    keypoints, descriptors = create_descriptors(image)\n",
    "    np.savetxt(f\"{preprocessed_path}/{fruit_type}/{image_name}_preprocessed.csv\", descriptors, delimiter=',')\n",
    "    des_dict = create_des_dict(ID, descriptors)\n",
    "\n",
    "    return des_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef503e-8fc3-4622-aeef-3006394a3440",
   "metadata": {},
   "source": [
    "### Reducing Dimension ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75c860-ce70-4cda-832c-c794a0cf0574",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stack Descriptors in a List ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33950818-62b0-4f6d-ae32-65459e7aca27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stacking verticaly the descriptors in a list to cluster them later\n",
    "def stack_descriptors():\n",
    "    print('Stacking Descriptors...')\n",
    "    t0 =time()\n",
    "    # Getting the list of descriptors with unique sized array\n",
    "    des_list = []\n",
    "    for i in range(len(descriptor_list)):\n",
    "        des_list.append(descriptor_list[i]['descriptors'])\n",
    "    \n",
    "    # Function to stack a descriptor vertically in a numpy array\n",
    "    def create_descriptors(x):\n",
    "        descriptor = np.vstack(interval[x])\n",
    "        return descriptor\n",
    "    \n",
    "    # To avoid overloading the memory, we will split the task\n",
    "    interval_list = []\n",
    "    for n in range(len(des_list)):\n",
    "        if (n+1)% 200 == 0:\n",
    "            interval_list.append(des_list[n-199:n+1])\n",
    "            if n > len(des_list)-200:\n",
    "                if n+1 != len(des_list):\n",
    "                    interval_list.append(des_list[n+1:])\n",
    "    \n",
    "    # Stacking all the descriptors vertically\n",
    "    descriptors = 'primer'\n",
    "    for interval in interval_list:\n",
    "        fraction = len(interval)\n",
    "        fraction_rdd = sc.parallelize([i for i in range(fraction)])\n",
    "        result_list = fraction_rdd.map(lambda x: create_descriptors(x)).collect()\n",
    "        result_list = np.vstack(result_list)\n",
    "        try:\n",
    "            descriptors = np.vstack((descriptors, result_list))\n",
    "        except:\n",
    "            descriptors = np.vstack(result_list)\n",
    "\n",
    "    ## K-Means working only on float, we will convert the descriptors\n",
    "    descriptors = descriptors.astype(float)\n",
    "\n",
    "    t1 = time()\n",
    "    print(\"Time taken to stack descriptors : {} s or {} min.\".format(t1-t0, (t1-t0)/60))\n",
    "    \n",
    "    return descriptors, des_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8decdd68-cf32-4947-92c1-5d1b40b03669",
   "metadata": {},
   "source": [
    "#### Creations of Bags of Visual Words ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41bd5b78-4c00-43f9-bf18-ef85957b1448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clustering the descriptors making Bags of Visual Words\n",
    "def create_BoVW(descriptors, des_list):\n",
    "    print('Clustering descriptors...')\n",
    "    k = int(round(np.sqrt(len(des_list)), 0))\n",
    "    print('Estimated number of clusters : {}'.format(k))\n",
    "    t0 = time()\n",
    "\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, init_size=3*k, random_state=0)\n",
    "    kmeans.fit(descriptors, k, 1)\n",
    "\n",
    "    voc = kmeans.cluster_centers_\n",
    "\n",
    "    t1 = time()\n",
    "    elapsed = t1 -t0\n",
    "    print('Clustering time : {:.2f} s.'.format(elapsed))\n",
    "    \n",
    "    return voc, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aece1-be38-468a-81fc-ace44505ba5e",
   "metadata": {},
   "source": [
    "#### Extract and Scale Image Features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0cb7f3f-c0bc-439d-931d-493c4e20f8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting and scaling the image features from the descriptors\n",
    "def image_features(voc, k, des_list):\n",
    "    print('Extracting and scaling image features...')\n",
    "    t0 = time()\n",
    "    # Extractions of the Images Features\n",
    "    img_features = np.zeros((len(des_list), k), 'float32')\n",
    "    for i in range(len(des_list)):\n",
    "        words, distance = vq(des_list[i], voc)\n",
    "        for w in words:\n",
    "            img_features[i][w] += 1\n",
    "\n",
    "    # Scaling of the features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_img_features = scaler.fit_transform(img_features)\n",
    "\n",
    "    t1 = time()\n",
    "    print(\"Time taken to extract and scale image features : {} s or {} min.\".format(t1-t0, (t1-t0)/60))\n",
    "    \n",
    "    return scaled_img_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e57dee-2b2f-4e17-9bf9-75b099a6588c",
   "metadata": {},
   "source": [
    "#### Apply the PCA ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3002ca7d-23e1-4d7f-acae-39733b76238e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing a dimension reduction by PCA on the features\n",
    "def test_pca(scaled_img_features):\n",
    "    # Testing the PCA\n",
    "    print('Testing Optimal Number of Components for the PCA')\n",
    "    PCA_df = pd.DataFrame(columns = ['Components', 'Variance', 'Time'])\n",
    "\n",
    "    max_features = scaled_img_features.shape[1]\n",
    "    for i in range(2, max_features):\n",
    "        t0 = time()\n",
    "        pca = PCA(n_components=i)\n",
    "        X_PCA = pca.fit_transform(scaled_img_features)\n",
    "        pca_var = pca.explained_variance_ratio_.sum()\n",
    "        t1 = time()\n",
    "        pca_time = t1-t0\n",
    "\n",
    "        PCA_df.loc[i, 'Components'] = i\n",
    "        PCA_df.loc[i, 'Variance'] = pca_var\n",
    "        PCA_df.loc[i, 'Time'] = pca_time\n",
    "\n",
    "    best_component = list(PCA_df[PCA_df['Variance'] > 0.95].index)[0]\n",
    "    print(\"Done. Optimal Number of Components is {}.\".format(best_component))\n",
    "    \n",
    "    return best_component, PCA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89bf9df-17b6-4791-b213-87be46151c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting the results of the test\n",
    "def plotting_test(best_component, PCA_df):\n",
    "    x = PCA_df['Components']\n",
    "    y = PCA_df['Variance']\n",
    "    labels = PCA_df['Time']\n",
    "\n",
    "    fig = plt.figure(figsize = (12,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y)\n",
    "    ax.text(1, 1, f'Best number of components = {best_component}')\n",
    "    plt.axhline(y= 0.95, color = 'r', linestyle='--')\n",
    "    plt.axvline(x=best_component, color = 'r', linestyle='--')\n",
    "    ax.set(\n",
    "        title='Analysis of Variance Explained over Number of Components',\n",
    "        xlabel='Number of Components',\n",
    "        ylabel='Variance Explained'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c990096-be9a-413b-9b0c-6eaec3163352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doing the PCA with the best number of components\n",
    "def doing_pca(scaled_img_features, best_component):\n",
    "    print('Operating Optimized PCA...')\n",
    "    t0 = time()\n",
    "    pca = PCA(n_components=best_component)\n",
    "    X_PCA = pca.fit_transform(scaled_img_features)\n",
    "    pca_var = pca.explained_variance_ratio_.sum()\n",
    "    t1 = time()\n",
    "    pca_time = t1-t0\n",
    "\n",
    "    print('PCA with {} components explains {:.2f} variance and is done in {:.2f} s.'\n",
    "          .format(best_component, pca_var, pca_time))\n",
    "    \n",
    "    return X_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896446e5-2abf-46a3-9057-0d36fa763aff",
   "metadata": {},
   "source": [
    "#### Save Reduced Features in Dataframe ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49dd3457-3e90-4652-9d4e-015f94c12967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the PCA Reduced Features\n",
    "def save_features(X_PCA):\n",
    "    print('Saving results...')\n",
    "    try :\n",
    "        des_df['PCA_Reduced_Image Features'] = des_df['PCA_Reduced_Image_Features'].astype(object)\n",
    "    except:\n",
    "        des_df['PCA_Reduced_Image_Features'] = np.nan\n",
    "        des_df['PCA_Reduced_Image_Features'] = des_df['PCA_Reduced_Image_Features'].astype(object)\n",
    "    \n",
    "    for i, v in des_df.iterrows():\n",
    "        des_df.loc[i, 'PCA_Reduced_Image_Features'] = X_PCA[i]\n",
    "        fruit_folder = data_df.loc[i, 'Type_of_fruit']\n",
    "        fruit_image = dot_split.split(data_df.loc[i, 'Image_name'])[0]\n",
    "        np.savetxt(f\"{preprocessed_path}/{fruit_folder}/{fruit_image}_reduced.csv\", X_PCA[i], delimiter=',')\n",
    "\n",
    "    des_df.to_csv(ressource_path + 'descriptors_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca44b8-13aa-4fba-bae4-e2925742d7e8",
   "metadata": {},
   "source": [
    "#### Compile All These Steps ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b9cb0e-7f56-4c27-9267-97d7d49ccf44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doing all the above steps\n",
    "def reduce_dimensions():\n",
    "    descriptors, des_list = stack_descriptors()\n",
    "    voc, k = create_BoVW(descriptors, des_list)\n",
    "    scaled_img_features = image_features(voc, k, des_list)\n",
    "    best_component, PCA_df = test_pca(scaled_img_features)\n",
    "    plotting_test(best_component, PCA_df)\n",
    "    X_PCA = doing_pca(scaled_img_features, best_component)\n",
    "    save_features(X_PCA)\n",
    "    print(\"Features saved in the file 'descriptors_list.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5f88e-bb9f-49a5-9f71-edc9a4e50302",
   "metadata": {},
   "source": [
    "## Creating the Dataframe ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775a687-1bed-49c0-bfc2-acb731ff164d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For a fruit type, create a path, a list of all the fruit, make a \n",
    "# new preprocessed directory and add them the missing fruits to the dataframe\n",
    "t0 = time()\n",
    "\n",
    "for fruit_type in fruit_type_list:\n",
    "    image_type_path = image_path + fruit_type\n",
    "    fruit_list_rdd = sc.parallelize(os.listdir(image_type_path))\n",
    "    os.makedirs(preprocessed_path + fruit_type, exist_ok=True)\n",
    "    fruits_to_append = fruit_list_rdd.map(lambda x: fill_df(fruit_type, x)).collect()\n",
    "    fruits_to_append = list(filter(None, fruits_to_append))\n",
    "    data_df = data_df.append(fruits_to_append, ignore_index=True, sort=True)\n",
    "\n",
    "data_df = data_df[['ID','Image_name', 'Type_of_fruit']]\n",
    "data_df.to_csv(ressource_path + 'fruits_index.csv', index=False)\n",
    "\n",
    "t1 = time()\n",
    "print(\"Time taken : {} s or {} min.\".format(t1-t0, (t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b942266-9bd8-4769-8a2e-a3329168711d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing images that are not already preprocessed\n",
    "t0 =time()\n",
    "descriptor_list =[]\n",
    "\n",
    "# Splitting the task in several to avoid tasks being too large\n",
    "for fruit_type in fruit_type_list:\n",
    "    fruit_type_masque = data_df[data_df['Type_of_fruit']==fruit_type]\n",
    "    images_list_rdd = sc.parallelize(fruit_type_masque['ID'])\n",
    "    fruit_type_descriptor_list = images_list_rdd.map(lambda ID: preprocessing_image(ID)).collect()\n",
    "    fruit_type_descriptor_list = list(filter(None, fruit_type_descriptor_list))\n",
    "    descriptor_list.extend(fruit_type_descriptor_list)\n",
    "        \n",
    "des_df = des_df.append(descriptor_list, ignore_index=True)\n",
    "des_df.to_csv(ressource_path + 'descriptors_list.csv', index=False)\n",
    "\n",
    "t1 =time()\n",
    "print(\"Time taken : {} s or {} min.\".format(t1-t0, (t1-t0)/60))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "762b42e2-6d90-4282-8a99-aa53775e1035",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting the image features and reducing their dimension\n",
    "reduce_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7dc58-b09b-434c-b40a-a9da56fed5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors, des_list = stack_descriptors()\n",
    "#voc, k = create_BoVW(descriptors, des_list)\n",
    "#scaled_img_features = image_features(voc, k, des_list)\n",
    "#best_component, PCA_df = test_pca(scaled_img_features)\n",
    "#plotting_test(best_component, PCA_df)\n",
    "#X_PCA = doing_pca(scaled_img_features, best_component)\n",
    "#save_features(X_PCA)\n",
    "#print(\"Features saved in the file 'descriptors_list.csv'.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe79eb58-bb67-463d-8bd6-557f53a50180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting some tests for later\n",
    "print('Stacking Descriptors...')\n",
    "t0 =time()\n",
    "# Getting the list of descriptors with unique sized array\n",
    "des_list = []\n",
    "for i in range(len(descriptor_list)):\n",
    "    des_list.append(descriptor_list[i]['descriptors'])\n",
    "\n",
    "# Function to stack a descriptor vertically in a numpy array\n",
    "def create_descriptors(x):\n",
    "    descriptor = np.vstack(interval[x])\n",
    "    return descriptor\n",
    "\n",
    "# To avoid overloading the memory, we will split the task\n",
    "interval_list = []\n",
    "for n in range(len(des_list)):\n",
    "    if (n+1)% 200 == 0:\n",
    "        interval_list.append(des_list[n-199:n+1])\n",
    "        if n > len(des_list)-200:\n",
    "            if n+1 != len(des_list):\n",
    "                interval_list.append(des_list[n+1:])\n",
    "\n",
    "# Stacking all the descriptors vertically\n",
    "descriptors_test = 'primer'\n",
    "for interval in interval_list[0:2]:\n",
    "    fraction = len(interval)\n",
    "    fraction_rdd = sc.parallelize([i for i in range(fraction)])\n",
    "    #fraction_rdd = sc.parallelize(interval)\n",
    "    result_list = fraction_rdd.map(lambda x: create_descriptors(x)).collect()\n",
    "    result_list = np.vstack(result_list)\n",
    "    try:\n",
    "        descriptors_test = np.vstack((descriptors_test, result_list))\n",
    "    except:\n",
    "        descriptors_test = np.vstack(result_list)\n",
    "\n",
    "## K-Means working only on float, we will convert the descriptors\n",
    "descriptors_test = descriptors_test.astype(float)\n",
    "\n",
    "t1 = time()\n",
    "print(\"Time taken to stack descriptors : {}s or {}min.\".format(t1-t0, (t1-t0)/60))\n",
    "\n",
    "des_list_test = des_list[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11302a29-b037-404a-9c2e-48c0edbf6f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clustering the descriptors making Bags of Visual Words with Pyspark \n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark import Row\n",
    "from pyspark.sql.types import FloatType, ArrayType,StructType,StructField\n",
    "\n",
    "def create_BoVW(descriptors, des_list):\n",
    "    print('Clustering descriptors...')\n",
    "    k = int(round(np.sqrt(len(des_list)), 0))\n",
    "    print('Estimated number of clusters : {}'.format(k))\n",
    "    t0 = time()\n",
    "    \n",
    "    #descriptors_rdd = sc.parallelize(descriptors)\n",
    "    #descriptors_df = pd.DataFrame(descriptors)\n",
    "    #rint(f\"Pandas's DataFrame Done in {time()-t0}s.\")\n",
    "    #descriptors_data = spark.createDataFrame(descriptors_df)\n",
    "    descriptors_data = spark.createDataFrame(descriptors.tolist(), ArrayType(FloatType(), containsNull=False)).toDF(\"features\")\n",
    "    print(f\"Spark's DataFrame  Done in {time()-t0}s.\")\n",
    "    print(descriptors_data.show(5))\n",
    "    #descriptors_data.show()\n",
    "    #descriptors_data = descriptors_rdd.map(lambda line: line[0].split(\" \")).toDF()\n",
    "    #descriptors_data.show()\n",
    "    \n",
    "    #clusters = KMeans.train(descriptors_rdd, k ,initializationMode='random')\n",
    "    #voc = clusters.centers[clusters.predict(descriptors)]\n",
    "    \n",
    "    kmeans = KMeans(k=k)\n",
    "    model = kmeans.fit(descriptors_data)\n",
    "    voc = np.asarray(model.clusterCenters())\n",
    "\n",
    "    t1 = time()\n",
    "    elapsed = t1 -t0\n",
    "    print('Clustering time : {:.2f}s.'.format(elapsed))\n",
    "    \n",
    "    return voc, k\n",
    "\n",
    "voc_test, k_test = create_BoVW(descriptors, des_list)\n",
    "print(type(voc_test))\n",
    "print(len(voc_test))\n",
    "print(voc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c565a-839c-4242-a8af-8c243e043257",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_zeta = time()\n",
    "total_time = t_zeta-t_omega\n",
    "print(f\"Total elapsed time for the notebook is : \\n{total_time} s, \\nor {total_time/60} min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c913f-b161-407a-a637-12cd94755578",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    print(\"testing {}.\".format(i), end=\"\\r\")\n",
    "    tm.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707034d1-23bb-4645-a633-5e40987f9c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
